{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = ImageFolder(r\"C:\\Users\\manoj\\OneDrive\\Desktop\\Program Files\\Python\\Intership1\\task3\\train\", transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d909a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extractor using MaxPooling and Flatten\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduce dimensions\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)  # Apply max pooling\n",
    "        return self.flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize feature extractor and move to device\n",
    "extractor = FeatureExtractor().to(device)\n",
    "\n",
    "# Extract features and labels\n",
    "features, labels = [], []\n",
    "for images, targets in dataloader:\n",
    "    images = images.to(device)  # Move images to GPU if available\n",
    "    extracted_features = extractor(images).cpu().numpy()  # Move back to CPU for NumPy processing\n",
    "    features.append(extracted_features)\n",
    "    labels.append(targets.numpy())\n",
    "\n",
    "features, labels = np.vstack(features), np.hstack(labels)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(features)\n",
    "data['target'] = labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm = SVC(kernel='linear').fit(X_train, y_train)\n",
    "\n",
    "# Predict and generate classification report\n",
    "predictions = svm.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
